---
title: "OBIS Marine Biodata Workshop"
author: "Stace Beaulieu, Ian Brunjes"
date: "2023-04-18"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(knitr)
library(kableExtra)
library(plotly)

source("ifcb_autoclass_eval.R")
source("dwc_transform.R")
```

# Overview

Notebook developed with R version 4.2.2

## Use Case

- Interoperable IFCB data product for the CA HAB Bulletin
- IFCB Dashboard to OBIS use case with automated classification
- Event core with Occurrence extension

## Authors

Ian Brunjes (SCCOOS), Stace Beaulieu (WHOI)
Prepared for OBIS IOOS Marine Biological Data Mobilization Workshop April 2023

**This is a prototype for testing purposes only.**
**A protocol is being developed to determine if and when appropriate to submit products from automated classification to OBIS.**

Sponsored by NOAA PCMHAB20 project “Harmful Algal Bloom Community Technology Accelerator”

# Workflow

Main steps in the workflow can be related to the [IFCB workflow diagram](https://raw.githubusercontent.com/hsosik/ifcb-analysis/master/Development/IFCB%20workflow%20chart.png) in the [ifcb-analysis wiki on GitHub](https://github.com/hsosik/ifcb-analysis/wiki)

Step: Classification
- Interpretation for the autoclass scores / transform automated classification into presence/absence

Step: Matching class labels to scientific names and IDs
- Match the class labels to scientific names in the World Register of Marine Species (WoRMS) taxonomic database.

Step: Summarization
- Calculate concentration as number of ROIs classified to a taxon divided by volume analyzed

Next step (not shown / would extend the diagram): Transforming to Darwin Core
- Map resulting data table into Darwin Core table(s)

## Target data product to standardize to Darwin Core:
Concentration of 2 genera of HAB taxa from an IFCB sample(s) (e.g., [here is a sample with autoclass available in HABDAC at Del Mar Mooring](https://ifcb.caloos.org/timeline?dataset=del-mar-mooring&bin=D20210620T221255_IFCB158)

Preconditions:
- IFCB Dashboard sample (bin) has autoclass csv file with scores per class label from automated classifier
- IFCB Dashboard sample has been populated with a dataset name, volume_analyzed, datetime, latitude, longitude, and depth
- For autoclass labels: A lookup table has been prepared with thresholds per class label

This workflow is being developed to meet the EU Horizon 2020 “Best practices and recommendations for plankton imagery data management” http://dx.doi.org/10.25607/OBP-1742

## Classification
In this step, we interpret the autoclass scores from the autoclass.csv file on the IFCB Dashboard. We will filter to the targeted class labels, apply a threshold per class label, and determine the “winning” class label per ROI, thus transforming the automated classification into a presence/absence table.

```{r message = FALSE}
target_labels = read_csv(here("data", "target_classification_labels.csv"))

kable(target_labels) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```


The order of operations is important in this filtering and thresholding process. If the filtering is applied prior to thresholding, the concentration is possibly (likely) to be overestimated by excluding other classes that may have higher scores.

**Thresholds used in this prototype are for testing purposes only.**

Our initial prototype will retain as ‘absence’ (zero count) when no ROIs exceed per-class threshold. However, we acknowledge that data providers may want to use a different per-class threshold to report absence, and might only want to report presence.

Once the output from this Classification step is matched to scientific names and IDs (next step) the intermediate table loosely corresponds to Level 1b SeaBASS file (classification per ROI).


```{r message = FALSE}
sample_bin = "D20210926T181303_IFCB158"
bin_details = get_bin_details(sample_bin)
# Thresholds used in this prototype are for testing purposes only.

bin_occurrences = get_bin_occurrences(sample_bin, target_labels)
kable(bin_occurrences) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```

## Matching class labels to scientific names and IDs
In this step, we use (a portion of) each autoclass label to query the API of the World Register of Marine Species (WoRMS) taxonomic database to return an accepted scientific name, its paired Aphia ID, and its taxon rank and kingdom.

```{r message = FALSE}
wm_records = get_worms_taxonomy(target_labels$intended_worms_taxon)
kable(wm_records) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```

## Summarization
In this step, we use the table from the Classification step and results from the Matching to WoRMS step to calculate concentration as number of ROIs classified to a taxon divided by volume analyzed per sample.

Output from the Summarization step loosely corresponds to Level 2 SeaBASS file.

```{r}
occurrences_summary = summarize_bin_occurrences(bin_details, bin_occurrences, target_labels)
kable(occurrences_summary) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```

## Transforming to Darwin Core
In this step, we transform the table from the Summarization step into two tables (an event table and an occurrence table) and add columns to meet OBIS and GBIF requirements for the Darwin Core Archive package.

We also add columns to meet the EU Horizon 2020 “Best practices and recommendations for plankton imagery data management” http://dx.doi.org/10.25607/OBP-1742

To assign the unique occurrenceID for the concentrations per taxon per sample we used eventID_taxonID, a pattern similar to the EU best practice, such that an individual included in the summed count would be represented by eventID_taxonID_roiID. Ultimately, we would like to test the DwC ResourceRelationship extension and/or DwC term associatedOrganisms to relate individuals to abundances reported to OBIS.

```{r}
# Build the Darwin Core Event table
event_tbl = build_event_table(bin_details)
kable(event_tbl) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```


```{r}
# Join occurrence summary with taxon records
wm_occurrences = left_join(occurrences_summary, wm_records, by = c("intended_worms_taxon" = "intended_worms_taxon"))

# Build the Darwin Core Occurrence table
occurrence_tbl = build_occurrence_table(wm_occurrences, bin_details)
kable(occurrence_tbl) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%")
```

## Extending workflow over a timespan

```{r message = FALSE}
# Demonstrating how to build the DwC tables for all bins within a span of time
start_date = "2021-09-25"
end_date = "2021-09-27"

# Read in classification input parameters
target_labels = read_csv(here("data", "target_classification_labels.csv"))

# Query WORMS lookup table
wm_records = get_worms_taxonomy(target_labels$intended_worms_taxon)

# Get the ifcb bins within time span and construct
bin_ids = get_bins_in_range(start_date, end_date)

event_tables = list()
occurrence_tables = list()

for(bin in bin_ids) {
  if (bin_has_autoclass(bin)) {
    # Build occurrence summary
    bin_details = get_bin_details(bin)
    bin_occurrences = get_bin_occurrences(bin, target_labels)
    occurrences_summary = summarize_bin_occurrences(bin_details, bin_occurrences, target_labels)
    
    # Build dwc event table
    event_tbl = build_event_table(bin_details)
    
    # Build dwc occurrence table
    wm_occurrences = left_join(occurrences_summary, wm_records, by = c("intended_worms_taxon" = "intended_worms_taxon"))
    occurrence_tbl = build_occurrence_table(wm_occurrences, bin_details)
    
    event_tables[bin] = list(event_tbl)
    occurrence_tables[bin] = list(occurrence_tbl)
  }
}

# Bind each per bin result into single event/occurrence table
event_tbl = bind_rows(event_tables)
occurrence_tbl = bind_rows(occurrence_tables)

# Save to output to .csv
write_csv(event_tbl, here("output", "event.csv"))
write_csv(occurrence_tbl, here("output", "occurrence.csv"))
```



### Aggregated event table

```{r}
kable(event_tbl) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%", height = "400px")
```




### Aggregated occurrence table

```{r}
kable(occurrence_tbl) %>% kable_material(c("striped", "hover")) %>% scroll_box(width = "100%", height = "400px")
```



### Visualizing results
```{r out.width="100%"} 

# Join event timestamp to occurrences
eo = left_join(occurrence_tbl, event_tbl, by = join_by(eventID)) %>%
  mutate(eventDate = as_datetime(eventDate)) %>%
  select(eventID, eventDate, scientificName, organismQuantity)


# Built plotly
p = eo %>% ggplot(aes(x=eventDate, y=organismQuantity, color = scientificName)) + geom_point() + geom_line() + labs(x = "", y = "organismQuantity (counts per milliliter)", title = paste0("Del Mar IFCB Occurrence Data (", start_date, " - ", end_date, ")"))

ggplotly(p) %>% layout(legend = list(title = "", x = 0.75, y = 0.9))
```

